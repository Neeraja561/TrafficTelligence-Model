# -*- coding: utf-8 -*-
"""Traffic_intelligence.ipnb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zx-KtBYalExkkyAL93xpSEsfsIZL8wgM
"""

#@title Part 1: Train the TrafficTelligence Model (Run This First)
# This cell downloads the data, preprocesses it, and trains the machine learning model.
# You only need to run this cell once per session.

# --- Step 1: Setup and Imports ---
print("--- Step 1: Setup and Imports ---")
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, r2_score
import warnings

warnings.filterwarnings('ignore')
print("Libraries imported successfully.\n")


# --- Step 2: Load and Explore Real-World Data ---
print("--- Step 2: Loading Real-World Traffic Data ---")
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz'
df = pd.read_csv(url, compression='gzip')

print(f"Successfully loaded dataset with {df.shape[0]} rows and {df.shape[1]} columns.\n")


# --- Step 3: Feature Engineering & Preprocessing ---
print("--- Step 3: Feature Engineering & Preprocessing ---")
df['date_time'] = pd.to_datetime(df['date_time'])
df['hour'] = df['date_time'].dt.hour
df['day_of_week'] = df['date_time'].dt.dayofweek
df['month'] = df['date_time'].dt.month
df['year'] = df['date_time'].dt.year

# Define our features (X) and target (y)
features = ['holiday', 'temp', 'rain_1h', 'snow_1h', 'clouds_all', 'weather_main', 'hour', 'day_of_week', 'month', 'year']
target = 'traffic_volume'

X = df[features]
y = df[target]

# Create a preprocessing pipeline
categorical_features = ['holiday', 'weather_main']
numerical_features = ['temp', 'rain_1h', 'snow_1h', 'clouds_all', 'hour', 'day_of_week', 'month', 'year']

preprocessor = ColumnTransformer(
    transformers=[
        ('num', 'passthrough', numerical_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ])
print("Preprocessing pipeline created.\n")


# --- Step 4: Model Training ---
print("--- Step 4: Model Training ---")
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', GradientBoostingRegressor(
        n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, loss='squared_error'
    ))
])

print("\nTraining the model pipeline... (This can take a few minutes)")
model_pipeline.fit(X_train, y_train)
print("Model training complete.\n")


# --- Step 5: Model Evaluation ---
print("--- Step 5: Model Evaluation ---")
y_pred = model_pipeline.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Model Performance on Test Data:")
print(f"  - Mean Absolute Error (MAE): {mae:.2f}")
print(f"  - R-squared (R²): {r2:.2f}")

# Visualize the results
sample_indices = np.random.choice(X_test.index, size=1000, replace=False)
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_test.loc[sample_indices], y=y_pred[y_test.index.isin(sample_indices)], alpha=0.6)
plt.plot([0, y_test.max()], [0, y_test.max()], '--r', linewidth=2, label='Perfect Prediction')
plt.title('Actual vs. Predicted Traffic Volume (Sample)')
plt.xlabel('Actual Volume')
plt.ylabel('Predicted Volume')
plt.legend(); plt.grid(True); plt.show()
print("\n✅ Part 1 is complete. You can now use the interactive form in Part 2.")

#@title Part 2: Interactive TrafficTelligence Predictions
#@markdown Adjust the values below to describe a traffic scenario, then run this cell.

# --- Create Interactive Form Elements ---
hour_of_day = 12 #@param {type:"slider", min:0, max:23, step:1}
day_name = 'Sunday' #@param ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
month = 10 #@param {type:"slider", min:1, max:12, step:1}
year = 2025 #@param {type:"number"}
#@markdown ---
#@markdown **Holiday and Weather Conditions**
holiday_type = 'None' #@param ['None', 'Columbus Day', 'Veterans Day', 'Thanksgiving Day', 'Christmas Day', 'New Years Day', 'Washingtons Birthday', 'Martin Luther King Jr Day', 'Independence Day', 'State Fair', 'Labor Day', 'Memorial Day']
main_weather = 'Clear' #@param ['Clear', 'Clouds', 'Rain', 'Drizzle', 'Mist', 'Haze', 'Fog', 'Snow', 'Thunderstorm', 'Squall', 'Smoke']
temperature_celsius = 15 #@param {type:"slider", min:-20, max:40, step:1}
rain_mm_last_hour = 1.5 #@param {type:"number"}
snow_mm_last_hour = 0.0 #@param {type:"number"}
cloud_coverage_percent = 10 #@param {type:"slider", min:0, max:100, step:1}
#@markdown ---

# --- Process User Inputs ---
# Map user-friendly inputs to the format the model expects
day_mapping = {"Monday": 0, "Tuesday": 1, "Wednesday": 2, "Thursday": 3, "Friday": 4, "Saturday": 5, "Sunday": 6}
day_of_week_numeric = day_mapping[day_name]

# The model was trained on temperature in Kelvin, so we convert from Celsius
temp_kelvin = temperature_celsius + 273.15

# Create a DataFrame from the user's inputs
new_data = pd.DataFrame({
    'holiday': [holiday_type],
    'temp': [temp_kelvin],
    'rain_1h': [rain_mm_last_hour],
    'snow_1h': [snow_mm_last_hour],
    'clouds_all': [cloud_coverage_percent],
    'weather_main': [main_weather],
    'hour': [hour_of_day],
    'day_of_week': [day_of_week_numeric],
    'month': [month],
    'year': [year]
})

# --- Make and Display Prediction ---
# Use the trained pipeline to predict on the new data
predicted_volume = model_pipeline.predict(new_data)

print("--- TrafficTelligence Prediction ---")
print(f"Scenario:")
print(f"  - Time: {hour_of_day:02d}:00 on a {day_name} in month {month}/{year}")
print(f"  - Conditions: {main_weather}, {temperature_celsius}°C, Holiday: {holiday_type}")
print("\n" + "="*40)
print(f"  ESTIMATED TRAFFIC VOLUME: {int(predicted_volume[0])} vehicles")
print("="*40)

